{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "env.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg import DDPG\n",
    "from td3 import TD3\n",
    "\n",
    "actor = TD3(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def get_experiences(env, actor, episodes=50):\n",
    "    for episode in range(0, episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        for t in itertools.count():\n",
    "            action = actor.act(obs)\n",
    "            obs2, reward, done, _ = env.step(action)\n",
    "            actor.remember(obs, action, reward, obs2, done)\n",
    "            obs = obs2\n",
    "            if done:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def train(env, actor, episodes=100):\n",
    "    returns = []\n",
    "    mean = 0\n",
    "    for episode in range(1, episodes+1):\n",
    "        obs = env.reset()\n",
    "        score = 0\n",
    "        for t in itertools.count():\n",
    "            action = actor.act(obs)\n",
    "            obs2, reward, done, _ = env.step(action)\n",
    "            actor.remember(obs, action, reward, obs2, done)  \n",
    "            actor.train(batch_size=256)\n",
    "            obs = obs2\n",
    "            score += reward\n",
    "            if done:\n",
    "                returns.append(score)\n",
    "                mean = np.mean(returns[-10:])\n",
    "                print(\"Episode: \" + str(episode) + \", Score: \" +str(score) + \", Mean Score: \" + str(mean))\n",
    "                if mean > 180:\n",
    "                    return returns\n",
    "                break    \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_experiences(env, actor, episodes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: -546.0058286997536, Mean Score: -546.0058286997536\n",
      "Episode: 2, Score: -102.1111414060409, Mean Score: -324.05848505289725\n",
      "Episode: 3, Score: -204.81715448622046, Mean Score: -284.311374864005\n",
      "Episode: 4, Score: -158.28594656737988, Mean Score: -252.8050177898487\n",
      "Episode: 5, Score: -113.47410062880428, Mean Score: -224.93883435763982\n",
      "Episode: 6, Score: -19.256802905137732, Mean Score: -190.6584957822228\n",
      "Episode: 7, Score: -283.8945032984567, Mean Score: -203.97792542739904\n",
      "Episode: 8, Score: -99.29878208587333, Mean Score: -190.89303250970835\n",
      "Episode: 9, Score: -127.05740958684099, Mean Score: -183.80018551827865\n",
      "Episode: 10, Score: -453.94660479681176, Mean Score: -210.81482744613194\n",
      "Episode: 11, Score: -363.0557747212094, Mean Score: -192.51982204827752\n",
      "Episode: 12, Score: -311.2626037217583, Mean Score: -213.43496827984927\n",
      "Episode: 13, Score: -427.4506675295366, Mean Score: -235.6983195841809\n",
      "Episode: 14, Score: -421.80150755612, Mean Score: -262.0498756830549\n",
      "Episode: 15, Score: -285.7748945579019, Mean Score: -279.27995507596466\n",
      "Episode: 16, Score: -126.93122094376365, Mean Score: -290.04739687982726\n",
      "Episode: 17, Score: -259.46943336457423, Mean Score: -287.604889886439\n",
      "Episode: 18, Score: -478.70734834308195, Mean Score: -325.5457465121599\n",
      "Episode: 19, Score: -218.02582580190918, Mean Score: -334.64258813366666\n",
      "Episode: 20, Score: -120.93617884580637, Mean Score: -301.34154553856615\n",
      "Episode: 21, Score: -118.24480846595522, Mean Score: -276.8604489130407\n",
      "Episode: 22, Score: -1598.7431036956777, Mean Score: -405.60849891043273\n",
      "Episode: 23, Score: -1203.644571310967, Mean Score: -483.22788928857574\n",
      "Episode: 24, Score: -566.4387081475082, Mean Score: -497.6916093477145\n",
      "Episode: 25, Score: -709.1050408292134, Mean Score: -540.0246239748456\n",
      "Episode: 26, Score: -640.2682662687268, Mean Score: -591.358328507342\n",
      "Episode: 27, Score: -461.18918210344924, Mean Score: -611.5303033812295\n",
      "Episode: 28, Score: -959.1786876442054, Mean Score: -659.577437311342\n",
      "Episode: 29, Score: -571.2670886564575, Mean Score: -694.9015635967968\n",
      "Episode: 30, Score: -598.3910101240353, Mean Score: -742.6470467246196\n",
      "Episode: 31, Score: -646.3423990870859, Mean Score: -795.4568057867327\n",
      "Episode: 32, Score: -642.5781637501747, Mean Score: -699.8403117921823\n",
      "Episode: 33, Score: -632.1086544821994, Mean Score: -642.6867201093057\n",
      "Episode: 34, Score: -568.4599406478155, Mean Score: -642.8888433593363\n",
      "Episode: 35, Score: -1751.6629673828672, Mean Score: -747.1446360147017\n",
      "Episode: 36, Score: -735.5601411625332, Mean Score: -756.6738235040823\n",
      "Episode: 37, Score: -898.1532529942057, Mean Score: -800.3702305931581\n",
      "Episode: 38, Score: -564.3804397871932, Mean Score: -760.8904058074568\n",
      "Episode: 39, Score: -625.9911511469601, Mean Score: -766.362812056507\n",
      "Episode: 40, Score: -441.8579531285911, Mean Score: -750.7095063569626\n",
      "Episode: 41, Score: -682.6277273673195, Mean Score: -754.338039184986\n",
      "Episode: 42, Score: -876.8650389435696, Mean Score: -777.7667267043255\n",
      "Episode: 43, Score: -1041.9091456143851, Mean Score: -818.7467758175441\n",
      "Episode: 44, Score: -507.17824895454277, Mean Score: -812.6186066482168\n",
      "Episode: 45, Score: -402.5502378821268, Mean Score: -677.7073336981427\n",
      "Episode: 46, Score: -407.52307159784993, Mean Score: -644.9036267416743\n",
      "Episode: 47, Score: -474.6907115144735, Mean Score: -602.5573725937011\n",
      "Episode: 48, Score: -1946.0456200818126, Mean Score: -740.7238906231631\n",
      "Episode: 49, Score: -350.62283689161546, Mean Score: -713.1870591976287\n",
      "Episode: 50, Score: -549.8746945352771, Mean Score: -723.9887333382973\n",
      "Episode: 51, Score: -485.1606999570401, Mean Score: -704.2420305972694\n"
     ]
    }
   ],
   "source": [
    "returns = train(env, actor, episodes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def run_episode(env, model, render=False, record=False):\n",
    "    images = []\n",
    "    obs = env.reset()\n",
    "    score = 0\n",
    "    for t in itertools.count():\n",
    "        if record:\n",
    "            images.append(env.render(mode='rgb_array'))\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = model.act(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        if done:\n",
    "            print(\"Score: \" + str(score))\n",
    "            env.close()\n",
    "            break\n",
    "            \n",
    "    if record:\n",
    "        imageio.mimsave('img/LunarTD3.gif', [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_episode(env, actor, render=True, record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(returns)), returns, label='Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
